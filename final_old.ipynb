{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phish Setlist Generator\n",
    "## By Kenny Callaghan\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "## Introduction: Problem\n",
    "\n",
    "Phish is an American rock band formed in 1983 in Burlington, VT. Over the course of their 30+ years of prolific touring, the band has gained a reputation for their whimsical sense of humor, whacky onstage antics, and virtuistic instrumental improvisation. All of this has underscored the quintessential aspect of a Phish concert: every show is unique, and no two shows are quite the same. The easiest way to ensure this is to develop a unique setlist (ordered set) of songs for each of their 1700+ shows. When a show begins, no one can be sure what songs will be played - not even the members of the band themselves! What if there was a way to predict a setlist before-hand?"
   ]
  },
  {
   "source": [
    "## Solution\n",
    "\n",
    "We would like to create an algorithm that can create Phish setlists from scratch - without any input from the band. We could do this by assembling a random list of songs, but we can do better. We can inform what song comes next in a setlist by looking at historical setlist data and extrapolating from there. We can start with a randomly-chosen song, either from a list of all previously-played songs, or from a smaller pool of all songs that have been used before as a set-opener. Then we can use a Natural Language Processing machine learning algorithm to predict the next songs that can be played in the setlist - similar to the word prediction system that is used by Google and other services to autocomplete searches or messages. We can do this a number of times until it reaches a natural conclusion."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data:\n",
    "\n",
    "The dataset that we are going to be working on is a list of every pair of songs ever performed together, formatted: \"song_title1\"+\"song_title2\" (song titles are in quotation marks, separated by a '+'). In the event that a given song is a set-opener (meaning it is the first song performed in a set), the first element in the pair will be \"\\*\\*\\*\\*\\*\". If a song is a set-closer (the last performed song in a set), that string will occupy the second space in the pair. In order to format the data in this way, we begin with phish.net, which is a fan-run website run by a dedicated group of individuals whom catalogue everything Phish-related. All setlist data was scraped from this site and put in a sqlite database in third normal form. The code for performing this task can be found at this public github repository: https://github.com/kcallaghan1/Phish-DB.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will help for later\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "source": [
    "### Pre-processing to desired format:\n",
    "\n",
    "First, we need to get a list of songs. Running the following commands from a sqlite terminal will give us a list of Phish sets as well as the songs contained in those sets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".open Phish.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".mode csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".headers on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".output songs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select setNumber, songName from (select * from songs join setlists using(songID));"
   ]
  },
  {
   "source": [
    "Then, we can use the following code to create a new document that will include set-closers:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def peek_line(f):\n",
    "    pos = f.tell()\n",
    "    line = f.readline()\n",
    "    f.seek(pos)\n",
    "    return line\n",
    "\n",
    "def count_lines(f):\n",
    "    pos = f.tell()\n",
    "    count = len(f.readlines())\n",
    "    f.seek(pos)\n",
    "    return count\n",
    "\n",
    "def create_pairs():\n",
    "    songs = open(\"songs.txt\", \"r\")\n",
    "    pairs = open(\"pairs_old.txt\", \"w\")\n",
    "    line_count = count_lines(songs)\n",
    "\n",
    "    #First two line of file are not useful\n",
    "    songs.readline()\n",
    "    line_count -= 1\n",
    "\n",
    "    for i in range(line_count - 1): # Offset by 2 because first 2 lines are headers\n",
    "        line = songs.readline()\n",
    "        next_line = peek_line(songs)\n",
    "        if(next_line):\n",
    "            song = line.split(\",\", 1)[1]\n",
    "            song = song[0: len(song) - 1]\n",
    "            if(\"\\\"\" not in song):\n",
    "                song = \"\\\"\" + song + \"\\\"\"\n",
    "\n",
    "\n",
    "            nextSong = next_line.split(\",\", 1)[1]\n",
    "            nextSong = nextSong[0: len(nextSong) - 1]\n",
    "            if(\"\\\"\" not in nextSong):\n",
    "                nextSong = \"\\\"\" + nextSong + \"\\\"\"\n",
    "\n",
    "            if(line.split(\",\",1)[0] != next_line.split(\",\",1)[0]):\n",
    "                nextSong = \"\\\"*****\\\"\"\n",
    "        pair = song + \"+\" + nextSong\n",
    "        pairs.write(pair + \"\\n\")\n",
    "\n",
    "    #Final line:\n",
    "    line = songs.readline()\n",
    "    song = line.split(\",\", 1)[1]\n",
    "    song = song[0: len(song) - 1]\n",
    "    pairs.write(\"\\\"\" + song + \"\\\"\" + \"+\" + \"\\\"*****\\\"\\n\")\n",
    "    songs.close()\n",
    "    pairs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code:\n",
    "create_pairs()"
   ]
  },
  {
   "source": [
    "This sets us up with set-closers, and this function will give us set-openers as well:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_openers():\n",
    "    pairs = open(\"pairs_old.txt\", \"r\")\n",
    "    pairs2 = open(\"pairs.txt\", \"w\")\n",
    "\n",
    "    lines = pairs.readlines()\n",
    "\n",
    "    #Add first song as opener:\n",
    "    pairs2.write(\"\\\"*****\\\"\" + \"+\" + lines[0].split(\"+\",1)[0] + \"\\n\")\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        one = line.split(\"+\",1)[0]\n",
    "        two = line.split(\"+\",1)[1]\n",
    "        pairs2.write(one + \"+\" + two)\n",
    "        if(two == \"\\\"*****\\\"\\n\"):\n",
    "            if(i < len(lines) - 1):\n",
    "                nextline = lines[i+1]\n",
    "                pairs2.write(\"\\\"*****\\\"\" + \"+\" + nextline.split(\"+\",1)[0] + \"\\n\")\n",
    "\n",
    "    pairs.close()\n",
    "    pairs2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code as well:\n",
    "add_openers()"
   ]
  },
  {
   "source": [
    "And now we have the data in the desired format in the pairs.txt file:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleData():\n",
    "    pairs = open(\"pairs.txt\", \"r\")\n",
    "    lines = pairs.readlines()\n",
    "    pairs.close()\n",
    "    rand = np.random.randint(len(lines) - 1)\n",
    "\n",
    "    for i in range(rand, rand+10):\n",
    "        print(str(i) + \": \" + lines[i][0:len(lines[i]) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21279: \"*****\"+\"Ya Mar\"\n21280: \"Ya Mar\"+\"Julius\"\n21281: \"Julius\"+\"Fee\"\n21282: \"Fee\"+\"Taste\"\n21283: \"Taste\"+\"Cavern\"\n21284: \"Cavern\"+\"Stash\"\n21285: \"Stash\"+\"The Lizards\"\n21286: \"The Lizards\"+\"Free\"\n21287: \"Free\"+\"Johnny B. Goode\"\n21288: \"Johnny B. Goode\"+\"*****\"\n"
     ]
    }
   ],
   "source": [
    "sampleData()"
   ]
  },
  {
   "source": [
    "We will populate the list with an ordered set of all songs performed:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "pairs = open(\"pairs.txt\", \"r\")\n",
    "lines = pairs.readlines()\n",
    "pairs.close()\n",
    "songs = []\n",
    "for i in range(0, len(lines), 2):\n",
    "    songs.append(lines[i].split(\"+\", 1)[0])\n",
    "    songs.append(lines[i].split(\"+\", 1)[1][0: len(lines[i].split(\"+\", 1)[1]) - 1])\n",
    "songs.append(\"\\\"*****\\\"\")"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "source": [
    "Now, we will create a sorted dictionary of unique songs:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs = np.unique(songs)\n",
    "unique_song_index = dict((c, i) for i, c in enumerate(unique_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\"*****\"', '\"Long Cool Woman in a Black Dress\"', '\"Proud Mary\"', '\"In the Midnight Hour\"', '\"Squeeze Box\"', '\"Roadhouse Blues\"', '\"Happy Birthday to You\"', '\"*****\"', '\"Scarlet Begonias\"', '\"Fire on the Mountain\"']\n\"*****\"\n"
     ]
    }
   ],
   "source": [
    "SONG_LENGTH = 10\n",
    "prev_songs = []\n",
    "next_songs = []\n",
    "for i in range(len(songs) - SONG_LENGTH):\n",
    "    prev_songs.append(songs[i:i+SONG_LENGTH])\n",
    "    next_songs.append(songs[i + SONG_LENGTH])\n",
    "print(prev_songs[0])\n",
    "print(next_songs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_songs), SONG_LENGTH, len(unique_songs)), dtype=bool)\n",
    "Y = np.zeros((len(next_songs), len(unique_songs)), dtype=bool)\n",
    "\n",
    "for i, each_songs in enumerate(prev_songs):\n",
    "    for j, each_song in enumerate(each_songs):\n",
    "        X[i, j, unique_song_index[each_song]] = 1\n",
    "    Y[i, unique_song_index[next_songs[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ True False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SONG_LENGTH, len(unique_songs))))\n",
    "model.add(Dense(len(unique_songs)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "296/296 [==============================] - 23s 57ms/step - loss: 5.0621 - accuracy: 0.1365 - val_loss: 5.4518 - val_accuracy: 0.1530\n",
      "Epoch 2/2\n",
      "296/296 [==============================] - 15s 52ms/step - loss: 4.0542 - accuracy: 0.2113 - val_loss: 5.4343 - val_accuracy: 0.1580\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=2, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: keras_next_song_model.h10\\assets\n",
      "INFO:tensorflow:Assets written to: keras_next_song_model.h10\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"keras_next_song_model.h10\")\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
    "\n",
    "model = load_model(\"keras_next_song_model.h10\")\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, SONG_LENGTH, len(unique_songs)))\n",
    "    for t, song in enumerate(text):\n",
    "        #print(song)\n",
    "        x[0, t, unique_song_index[song]] = 1\n",
    "    return x\n",
    "    \n",
    "prepare_input(songs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    if(text == \"\"):\n",
    "        return(\"0\")\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_songs[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_setlist():\n",
    "    setlist = []\n",
    "    #setlist.append(songs[np.random.randint(len(songs))])\n",
    "    setlist.append(\"\\\"*****\\\"\")\n",
    "    go = True\n",
    "    num = 1\n",
    "    setEnt = 1\n",
    "    idx = 1\n",
    "    while(num < 4 and idx < 25):\n",
    "        rand = np.random.randint(SONG_LENGTH)\n",
    "        if(idx <= SONG_LENGTH):\n",
    "            new_song = predict_completions(setlist[0:idx], SONG_LENGTH)[rand]\n",
    "        else:\n",
    "            new_song = predict_completions(setlist[idx - SONG_LENGTH: idx], SONG_LENGTH)[rand]\n",
    "        if(new_song == \"\\\"*****\\\"\" and (setEnt > 6 or num >= 2)):\n",
    "            num += 1\n",
    "            setlist.append(new_song)\n",
    "            setEnt = 0\n",
    "        elif(new_song in setlist):\n",
    "            idx -= 1 \n",
    "        else:\n",
    "            setlist.append(new_song)\n",
    "        idx += 1\n",
    "        setEnt += 1\n",
    "    return setlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\"*****\"', '\"Frankenstein\"', '\"Good Times Bad Times\"', '\"Lawn Boy\"', '\"Chalk Dust Torture\"', '\"Maze\"', '\"Run Like an Antelope\"', '\"Mike\\'s Song\"', '\"Harpua\"', '\"Weekapaug Groove\"', '\"The Horse\"', '\"Cold as Ice\"', '\"Love You\"', '\"*****\"', '\"Sweet Adeline\"', '\"Big Black Furry Creature from Mars\"', '\"Runaway Jim\"', '\"Amazing Grace\"', '\"Llama\"', '\"Sparkle\"', '\"The Landlady\"', '\"Suzy Greenberg\"', '\"It\\'s Ice\"', '\"Horn\"', '\"Rift\"']\n"
     ]
    }
   ],
   "source": [
    "setlist = generate_setlist()\n",
    "print(setlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}